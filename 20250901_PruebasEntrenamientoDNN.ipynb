{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch, time\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones (normalización simple a [0,1])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # asegura canal único\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga dataset desde la carpeta raíz generada por TINTOlib\n",
    "ruta_carpeta_actual = os.getcwd()\n",
    "data_dir  = os.path.join(ruta_carpeta_actual, \"PuntosMuestra_CR_tinto_synthetic_images\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # si vas a ViT\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 02 eliminada (índice 1).\n",
      "Clases activas: ['01', '03', '04', '06', '07', '10']\n",
      "Mapping nuevo: {'01': 0, '03': 1, '04': 2, '06': 3, '07': 4, '10': 5}\n"
     ]
    }
   ],
   "source": [
    "# 1) quitar clase \"02\"\n",
    "desc_cat = \"02\"\n",
    "if desc_cat in dataset.class_to_idx:\n",
    "    idx_c2 = dataset.class_to_idx[desc_cat]\n",
    "    dataset.samples = [s for s in dataset.samples if s[1] != idx_c2]\n",
    "    dataset.targets = [t for t in dataset.targets if t != idx_c2]\n",
    "    # eliminamos la clase del listado (actualizaremos el mapping abajo)\n",
    "    print(f\"Clase {desc_cat} eliminada (índice {idx_c2}).\")\n",
    "else:\n",
    "    print(f\"ℹ️ No existe carpeta {desc_cat} en dataset.class_to_idx !\")\n",
    "\n",
    "# 2) RE-MAPEAR etiquetas a 0..K-1\n",
    "unique_old = sorted(set(t for _, t in dataset.samples))\n",
    "old2new = {old:i for i, old in enumerate(unique_old)}\n",
    "\n",
    "dataset.samples = [(p, old2new[t]) for (p, t) in dataset.samples]\n",
    "dataset.targets = [old2new[t] for t in dataset.targets]\n",
    "\n",
    "# reconstruir class_to_idx y classes coherentes\n",
    "# invertimos el mapping original para recuperar nombres de carpeta por índice antiguo\n",
    "idx2class = {v:k for k,v in dataset.class_to_idx.items()}\n",
    "dataset.class_to_idx = {idx2class[old]: new for old, new in old2new.items()}\n",
    "# ordenar por índice nuevo para que 'classes' quede alineado a 0..K-1\n",
    "dataset.classes = [c for c,_ in sorted(dataset.class_to_idx.items(), key=lambda kv: kv[1])]\n",
    "\n",
    "print(\"Clases activas:\", dataset.classes)\n",
    "print(\"Mapping nuevo:\", dataset.class_to_idx)\n",
    "num_classes = len(dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "n = len(dataset)\n",
    "n_train = int(0.7*n)\n",
    "train_ds, test_ds = torch.utils.data.random_split(dataset, [n_train, n-n_train])\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dl  = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo entrenamiento y tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes, in_ch=1):\n",
    "        super().__init__()\n",
    "        self.feats = nn.Sequential(\n",
    "            nn.Conv2d(in_ch,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,3,padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)            # independiente del tamaño HxW\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32,128), nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.head(self.feats(x))\n",
    "\n",
    "num_classes = len(set(lbl for _, lbl in dataset.samples))\n",
    "model = SmallCNN(num_classes=num_classes, in_ch=3)    # in_ch=1 por Grayscale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱ CNN/ViT – entrenamiento (3 ep): 457.52s\n",
      "⏱ CNN/ViT – predicción: 35.730s  (4.08 ms/muestra)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt  = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# --- tiempo de entrenamiento (1-3 épocas para prueba) ---\n",
    "epochs = 3\n",
    "t0 = time.perf_counter()\n",
    "for _ in range(epochs):\n",
    "    model.train()\n",
    "    for x,y in train_dl:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model(x), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "t1 = time.perf_counter()\n",
    "fit_s = t1 - t0\n",
    "print(f\"⏱ CNN/ViT – entrenamiento ({epochs} ep): {fit_s:.2f}s\")\n",
    "\n",
    "# --- tiempo de predicción ---\n",
    "t0 = time.perf_counter()\n",
    "y_true, y_pred = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x,y in test_dl:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().tolist()\n",
    "        y_pred += preds\n",
    "        y_true += y.tolist()\n",
    "t1 = time.perf_counter()\n",
    "pred_s = t1 - t0\n",
    "print(f\"⏱ CNN/ViT – predicción: {pred_s:.3f}s  ({pred_s/len(y_true)*1000:.2f} ms/muestra)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA: 0.5189497716894977\n",
      "F1 macro: 0.11388346109524526\n",
      "Matriz de confusión:\n",
      " [[   0 2501    0    0    0    0]\n",
      " [   0 4546    0    0    0    0]\n",
      " [   0  333    0    0    0    0]\n",
      " [   0  362    0    0    0    0]\n",
      " [   0  393    0    0    0    0]\n",
      " [   0  625    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"OA:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1 macro:\", f1_score(y_true, y_pred, average='macro'))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tintoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
