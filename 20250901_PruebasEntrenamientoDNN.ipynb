{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones (normalización simple a [0,1])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # asegura canal único\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga dataset desde la carpeta raíz generada por TINTOlib\n",
    "ruta_carpeta_actual = os.getcwd()\n",
    "data_dir  = os.path.join(ruta_carpeta_actual, \"PuntosMuestra_CR_tinto_synthetic_images\")\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Split train/test\n",
    "n = len(dataset)\n",
    "n_train = int(0.7*n)\n",
    "train_ds, test_ds = torch.utils.data.random_split(dataset, [n_train, n-n_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dl  = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.head = None  # se define luego\n",
    "\n",
    "    def build_head(self, x_sample, num_classes):\n",
    "        with torch.no_grad():\n",
    "            f = self.conv(x_sample).flatten(1).shape[1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(f,128), nn.ReLU(),\n",
    "            nn.Linear(128,num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv(x).flatten(1)\n",
    "        return self.head(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([32, 1, 20, 20])\n",
      "Num clases: 7\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_dl))\n",
    "print(\"Batch shape:\", x.shape)  # [B,1,H,W]\n",
    "print(\"Num clases:\", len(dataset.classes))\n",
    "\n",
    "model = SmallCNN(num_classes=len(dataset.classes))\n",
    "x,_ = next(iter(train_dl))\n",
    "model.build_head(x, num_classes=len(dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Acc=0.652\n",
      "Epoch 2: Acc=0.814\n",
      "Epoch 3: Acc=0.825\n",
      "Epoch 4: Acc=0.824\n",
      "Epoch 5: Acc=0.822\n",
      "Epoch 6: Acc=0.827\n",
      "Epoch 7: Acc=0.824\n",
      "Epoch 8: Acc=0.828\n",
      "Epoch 9: Acc=0.831\n",
      "Epoch 10: Acc=0.827\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for x,y in train_dl:\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model(x), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    correct=total=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dl:\n",
    "            pred = model(x).argmax(1)\n",
    "            correct += (pred==y).sum().item()\n",
    "            total += y.numel()\n",
    "    print(f\"Epoch {epoch+1}: Acc={correct/total:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b37e52360e4201f7e82df0e4224bd8a8fcfc836b7bbaa6261cc3ae6ad0b97aa1"
  },
  "kernelspec": {
   "display_name": "Python 3.12.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
