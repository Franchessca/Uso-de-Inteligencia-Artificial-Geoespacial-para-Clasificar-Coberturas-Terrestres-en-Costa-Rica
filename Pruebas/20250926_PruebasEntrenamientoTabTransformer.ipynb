{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685c0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Desactivar detección/distribución MPI en Lightning (Windows/CPU) ----\n",
    "import os\n",
    "# Fuerza entrenamiento en CPU y en un solo proceso\n",
    "os.environ[\"LIGHTNING_LAUNCHER\"] = \"none\"   # evita lanzadores MPI/SLURM/etc.\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"              # sin distribución\n",
    "os.environ[\"PL_TORCH_DISTRIBUTED_BACKEND\"] = \"\"  # no intentes backends dist.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"     # por si intenta ver GPUs\n",
    "os.environ[\"PYTORCH_LIGHTNING_DISABLE_PROGRESS_BAR\"] = \"1\"  # ⛔ barra de progreso\n",
    "# (opcional) reduce hilos para evitar overhead\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6e3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models.tab_transformer import TabTransformerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40a5ad",
   "metadata": {},
   "source": [
    "# Modelo TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37a294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_carpeta_actual = os.getcwd()\n",
    "ruta_carpeta_raiz = os.path.dirname(ruta_carpeta_actual)\n",
    "csv_path  = os.path.join(ruta_carpeta_raiz, \"dataset\", \"PuntosMuestra_CR_2023.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "# c:\\Users\\Fran\\Documents\\2025-2_Seminario2\\Uso-de-Inteligencia-Artificial-Geoespacial-para-Clasificar-Coberturas-Terrestres-en-Costa-Rica\\dataset\\PuntosMuestra_CR_2023.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9ccbb",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9db7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar la categoria 2 del dataset\n",
    "df = df[df[\"CATEGORIA\"] != 2].copy()\n",
    "\n",
    "# Remapear categorías a 0..K-1\n",
    "clases_unicas = sorted(df[\"CATEGORIA\"].unique())\n",
    "mapa = {old: new for new, old in enumerate(clases_unicas)}\n",
    "df[\"CATEGORIA\"] = df[\"CATEGORIA\"].map(mapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34146a7e",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b39f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "y = df[\"CATEGORIA\"].values\n",
    "X = df.drop(columns=[\"CATEGORIA\",\"lon\",\"lat\",\"year\"])\n",
    "\n",
    "# Escalar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Reconstruir dataframe final\n",
    "df_final = pd.concat([X_scaled, pd.Series(y, name=\"CATEGORIA\")], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003af7a",
   "metadata": {},
   "source": [
    "## Division de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787b46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_final, test_size=0.3, random_state=42, stratify=df_final[\"CATEGORIA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd853337",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41390fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:35:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">445</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:35:12\u001b[0m,\u001b[1;36m445\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[\"CATEGORIA\"],\n",
    "    continuous_cols=X.columns.tolist(),\n",
    "    categorical_cols=[],\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False,\n",
    "    batch_size=256,\n",
    "    max_epochs=15,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"classification\",\n",
    "    metrics=[\"accuracy\", \"f1\"],\n",
    "    # num_classes ya no se pasa aquí\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "# ⚠️ Usa métricas válidas: \"accuracy\", \"precision\", \"recall\"\n",
    "# Si quieres F1, la calculamos después manualmente con sklearn\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"classification\",\n",
    "    metrics=[\"accuracy\"],   # solo métricas soportadas\n",
    ")\n",
    "\n",
    "# --- Crear modelo ---\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc35ed30",
   "metadata": {},
   "source": [
    "## Entrena modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58336b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:35:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">477</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:35:12\u001b[0m,\u001b[1;36m477\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:35:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">482</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:35:12\u001b[0m,\u001b[1;36m482\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:35:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">499</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:35:12\u001b[0m,\u001b[1;36m499\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:35:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">522</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:35:12\u001b[0m,\u001b[1;36m522\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:35:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m18:35:12\u001b[0m,\u001b[1;36m548\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ TabTransformerBackbone │  271 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding2dLayer       │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ LinearHead             │     84 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss       │      0 │ train │\n",
       "└───┴──────────────────┴────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabTransformerBackbone │  271 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding2dLayer       │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ LinearHead             │     84 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss       │      0 │ train │\n",
       "└───┴──────────────────┴────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 271 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 271 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 119                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 271 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 271 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 119                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Entrena (sin barra de progreso) ---\u001b[39;00m\n\u001b[32m      2\u001b[39m t0 = time.perf_counter()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtabular_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# <- clave: lista vacía\u001b[39;00m\n\u001b[32m      4\u001b[39m fit_s = time.perf_counter() - t0\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# --- Evalúa ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_tabular\\tabular_model.py:806\u001b[39m, in \u001b[36mTabularModel.fit\u001b[39m\u001b[34m(self, train, validation, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule, cache_data, handle_oom)\u001b[39m\n\u001b[32m    792\u001b[39m         warnings.warn(\n\u001b[32m    793\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtrain data and datamodule is provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    794\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Ignoring the train data and using the datamodule.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    795\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Set either one of them to None to avoid this warning.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m model = \u001b[38;5;28mself\u001b[39m.prepare_model(\n\u001b[32m    798\u001b[39m     datamodule,\n\u001b[32m    799\u001b[39m     loss,\n\u001b[32m   (...)\u001b[39m\u001b[32m    803\u001b[39m     optimizer_params \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[32m    804\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_oom\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_tabular\\tabular_model.py:680\u001b[39m, in \u001b[36mTabularModel.train\u001b[39m\u001b[34m(self, model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\u001b[39m\n\u001b[32m    678\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mTraining Started\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OutOfMemoryHandler(handle_oom=handle_oom) \u001b[38;5;28;01mas\u001b[39;00m oom_handler:\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m oom_handler.oom_triggered:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OOMException(\n\u001b[32m    683\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOOM detected during Training. Try reducing your batch_size or the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    684\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m model parameters.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    685\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/n\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33mOriginal Error: \u001b[39m\u001b[33m\"\u001b[39m + oom_handler.oom_msg\n\u001b[32m    686\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:538\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    536\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     50\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:574\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    568\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    569\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    570\u001b[39m     ckpt_path,\n\u001b[32m    571\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    572\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    573\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    577\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:981\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m    978\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m981\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    986\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1023\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m   1025\u001b[39m         \u001b[38;5;28mself\u001b[39m.fit_loop.run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1049\u001b[39m, in \u001b[36mTrainer._run_sanity_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.reset_results()\n\u001b[32m   1047\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.reset_metrics()\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_sanity_check_start\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[32m   1052\u001b[39m val_loop.run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:218\u001b[39m, in \u001b[36m_call_callback_hooks\u001b[39m\u001b[34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[32m    217\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback.state_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    222\u001b[39m     pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\progress\\rich_progress.py:381\u001b[39m, in \u001b[36mRichProgressBar.on_sanity_check_start\u001b[39m\u001b[34m(self, trainer, pl_module)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_sanity_check_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[33m\"\u001b[39m\u001b[33mpl.Trainer\u001b[39m\u001b[33m\"\u001b[39m, pl_module: \u001b[33m\"\u001b[39m\u001b[33mpl.LightningModule\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\progress\\rich_progress.py:341\u001b[39m, in \u001b[36mRichProgressBar._init_progress\u001b[39m\u001b[34m(self, trainer)\u001b[39m\n\u001b[32m    339\u001b[39m reconfigure(**\u001b[38;5;28mself\u001b[39m._console_kwargs)\n\u001b[32m    340\u001b[39m \u001b[38;5;28mself\u001b[39m._console = get_console()\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_console\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclear_live\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28mself\u001b[39m._metric_component = MetricsTextColumn(\n\u001b[32m    343\u001b[39m     trainer,\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m.theme.metrics,\n\u001b[32m    345\u001b[39m     \u001b[38;5;28mself\u001b[39m.theme.metrics_text_delimiter,\n\u001b[32m    346\u001b[39m     \u001b[38;5;28mself\u001b[39m.theme.metrics_format,\n\u001b[32m    347\u001b[39m )\n\u001b[32m    348\u001b[39m \u001b[38;5;28mself\u001b[39m.progress = CustomProgress(\n\u001b[32m    349\u001b[39m     *\u001b[38;5;28mself\u001b[39m.configure_columns(trainer),\n\u001b[32m    350\u001b[39m     \u001b[38;5;28mself\u001b[39m._metric_component,\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     console=\u001b[38;5;28mself\u001b[39m._console,\n\u001b[32m    354\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fran\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\rich\\console.py:847\u001b[39m, in \u001b[36mConsole.clear_live\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Clear the Live instance. Used by the Live context manager (no need to call directly).\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m847\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_live_stack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: pop from empty list"
     ]
    }
   ],
   "source": [
    "# --- Entrena (sin barra de progreso) ---\n",
    "t0 = time.perf_counter()\n",
    "tabular_model.fit(train=train, validation=test, callbacks=[])  # <- clave: lista vacía\n",
    "fit_s = time.perf_counter() - t0\n",
    "\n",
    "# --- Evalúa ---\n",
    "t0 = time.perf_counter()\n",
    "resultados = tabular_model.evaluate(test)\n",
    "pred_s = time.perf_counter() - t0\n",
    "\n",
    "# Predicciones\n",
    "preds = tabular_model.predict(test)\n",
    "y_true = test[\"CATEGORIA\"].tolist()\n",
    "y_pred = preds[\"prediction\"].tolist()\n",
    "\n",
    "print(\"Resultados en test:\", resultados)\n",
    "print(f\"⏱ Tiempo entrenamiento: {fit_s:.2f}s | inferencia: {pred_s:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd73bf3",
   "metadata": {},
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ead959",
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = accuracy_score(y_true, y_pred)\n",
    "f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
    "print(\"OA:\", oa)\n",
    "print(\"F1-macro:\", f1m)\n",
    "print(\"Reporte clasificación:\\n\", classification_report(y_true, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d4652",
   "metadata": {},
   "source": [
    "## Registrar información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb17312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import importlib, utils_log\n",
    "importlib.reload(utils_log)\n",
    "from utils_log import log_row\n",
    "\n",
    "carpeta_actual = ruta_carpeta_actual.split(\"\\\\\")[-1]\n",
    "dataset_utilizado = csv_path.split(\"\\\\\")[-1]\n",
    "\n",
    "log_row(\n",
    "  script=\"20250901_PruebasEntrenamientoRF.ipynb\",\n",
    "  algoritmo=\"RandomForest\",\n",
    "  dataset=dataset_utilizado,\n",
    "  clases_removidas=[2],\n",
    "  seed=42,\n",
    "  n_train=len(y_train), n_test=len(y_test),\n",
    "  n_features=X.shape[1], num_classes=len(sorted(y.unique())),\n",
    "  fit_seconds=train_time_s,                     # tiempo de rf.fit(...)\n",
    "  pred_seconds=pred_time_s,                   # tiempo de rf.predict(...)\n",
    "  ms_per_sample=(pred_time_s/len(y_test))*1000,\n",
    "  OA=oa, F1_macro=f1m,\n",
    "  carpeta=carpeta_actual\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tintoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
