{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EybOZ6hSjpCF"
   },
   "source": [
    "<h1><font color=\"#113D68\" size=6>TINTOlib: Converting Tidy Data into Synthetic Images</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Template problem with a Vision Transformer (ViT)</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#113D68\" size=3>Raúl García-Castro</font><br>\n",
    "<font color=\"#113D68\" size=3>Jiayun Liu</font><br>\n",
    "</div>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8311,
     "status": "ok",
     "timestamp": 1729271676773,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "PeeBbGxlpjFp",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manwest/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tifffile as tifi\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "from keras import ops\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (mean_absolute_error, mean_absolute_percentage_error,\n",
    "                             mean_squared_error, r2_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# TensorFlow and Keras\n",
    "from keras import layers, models, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import (Activation, BatchNormalization, concatenate,\n",
    "                                     Conv2D, Dense, Dropout, Flatten, Input,\n",
    "                                     LayerNormalization, MaxPool2D, MaxPooling2D)\n",
    "from keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adadelta, Adam, Adamax, SGD, AdamW\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.combination import Combination\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.featureWrap import FeatureWrap\n",
    "from TINTOlib.bie import BIE\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "SEED = 64\n",
    "#torch.manual_seed(SEED)\n",
    "#torch.cuda.manual_seed(SEED)\n",
    "#torch.cuda.manual_seed_all(SEED)\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729271676774,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "UIt0pGgtiCyr",
    "outputId": "f26ca72c-1f07-44cd-f70a-e6df5091eca6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O3</th>\n",
       "      <th>TMP</th>\n",
       "      <th>RH</th>\n",
       "      <th>1/RH</th>\n",
       "      <th>WSP</th>\n",
       "      <th>WDR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>3.2</td>\n",
       "      <td>346.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>3.4</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      O3   TMP    RH      1/RH  WSP    WDR  class\n",
       "0  163.0  28.2  17.0  0.058824  3.2  346.0      1\n",
       "1  170.0  28.9  23.0  0.043478  3.4  355.0      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../dataset_train.csv\"\n",
    "\n",
    "#Read CSV\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729271676774,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "ZJzBeHtwiCyr",
    "outputId": "280d0ed8-1e46-466e-bc70-0018eb2cd06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the dataframe\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# Calculate number of columns - 1\n",
    "columns_minus_one = num_columns - 1\n",
    "\n",
    "# Calculate the square root for image size\n",
    "import math\n",
    "image_size = math.ceil(math.sqrt(columns_minus_one))\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729271676774,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "NiCFhd9eiCyr"
   },
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"supervised\"\n",
    "#problem_type = \"regression\"\n",
    "pixelTML = 30\n",
    "pixel = 40\n",
    "## zoom para ampliar la imagen\n",
    "image_model = REFINED(problem=problem_type, random_seed=SEED, zoom=2, n_processors=8)\n",
    "image_model = IGTD(problem= problem_type, random_seed=SEED, scale=[4,4], zoom=2)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "results_folder = \"IGTD\"\n",
    "images_folder = \"IGTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40977,
     "status": "ok",
     "timestamp": 1729271717747,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "cerdfl_1irxZ",
    "outputId": "c91f1298-30c1-4cda-c911-71eb7956631b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGTD/supervised.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAYAAADED76LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAABPAAAATwFjiv3XAAAAQklEQVR4nKXMsQ3AIAwAwSMKIzAGQzA4e3gYS06dJhT5+vRt712w1gK9dzDGAJdDd0SAOSfIzBc4HlpV1Rc4Hv6DB8dwDlcQZhA6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 8x8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Generate the images if the folder does not exist\n",
    "if not os.path.exists(images_folder):\n",
    "    #Generate thet images\n",
    "    image_model.fit_transform(df, images_folder)\n",
    "else:\n",
    "    print(\"The images are already generated\")\n",
    "\n",
    "img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "print(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1729271717747,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "rvHDCZ-Iirx1"
   },
   "outputs": [],
   "source": [
    "imgs = pd.read_csv(img_paths)\n",
    "\n",
    "#imgs[\"images\"]= images_folder + \"\\\\\" + imgs[\"images\"]\n",
    "imgs[\"images\"]= images_folder + \"/\" + imgs[\"images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>O3</th>\n",
       "      <th>TMP</th>\n",
       "      <th>RH</th>\n",
       "      <th>1/RH</th>\n",
       "      <th>WSP</th>\n",
       "      <th>WDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IGTD/01/000000.png</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>28.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>3.2</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IGTD/01/000001.png</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>28.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>3.4</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IGTD/01/000002.png</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>28.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>4.4</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IGTD/01/000003.png</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>27.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>4.7</td>\n",
       "      <td>357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IGTD/01/000004.png</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>5.2</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23804</th>\n",
       "      <td>IGTD/00/023804.png</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>4.6</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23805</th>\n",
       "      <td>IGTD/00/023805.png</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.6</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>4.5</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23806</th>\n",
       "      <td>IGTD/00/023806.png</td>\n",
       "      <td>21.285714</td>\n",
       "      <td>19.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>3.9</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23807</th>\n",
       "      <td>IGTD/00/023807.png</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>3.6</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23808</th>\n",
       "      <td>IGTD/00/023808.png</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>3.3</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23809 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   images          O3   TMP    RH      1/RH  WSP    WDR\n",
       "0      IGTD/01/000000.png  163.000000  28.2  17.0  0.058824  3.2  346.0\n",
       "1      IGTD/01/000001.png  170.000000  28.9  23.0  0.043478  3.4  355.0\n",
       "2      IGTD/01/000002.png  181.000000  28.9  28.0  0.035714  4.4  345.0\n",
       "3      IGTD/01/000003.png  171.000000  27.4  32.0  0.031250  4.7  357.0\n",
       "4      IGTD/01/000004.png  124.000000  26.0  37.0  0.027027  5.2  355.0\n",
       "...                   ...         ...   ...   ...       ...  ...    ...\n",
       "23804  IGTD/00/023804.png   25.000000  21.3  90.0  0.011111  4.6  358.0\n",
       "23805  IGTD/00/023805.png   23.000000  20.6  89.0  0.011236  4.5  343.0\n",
       "23806  IGTD/00/023806.png   21.285714  19.1  91.0  0.010989  3.9  359.0\n",
       "23807  IGTD/00/023807.png   16.000000  18.9  91.0  0.010989  3.6  356.0\n",
       "23808  IGTD/00/023808.png   20.000000  18.5  91.0  0.010989  3.3  356.0\n",
       "\n",
       "[23809 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = imgs.rename(columns={'class': 'values'})\n",
    "\n",
    "combined_dataset = pd.concat([imgs,df],axis=1)\n",
    "combined_dataset\n",
    "# Drop target column and values which is a copy of target column\n",
    "df_x = combined_dataset.drop(df.columns[-1],axis=1).drop(\"values\",axis=1)\n",
    "df_y = combined_dataset[\"values\"]\n",
    "\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2829,
     "status": "ok",
     "timestamp": 1729271720569,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "veReOdAyiryJ",
    "outputId": "8a7a8df8-c8ac-475b-a11e-0e244ceabe02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (8, 8, 1)\n",
      "Attributres:  6\n",
      "Image size (pixels): 8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED)\n",
    "\n",
    "#TIDY DATA SPLITTED\n",
    "X_train_num = X_train.drop(\"images\",axis=1)\n",
    "X_val_num = X_val.drop(\"images\",axis=1)\n",
    "X_test_num = X_test.drop(\"images\",axis=1)\n",
    "\n",
    "#IMAGES\n",
    "# For 3 channels (RGB)\n",
    "\"\"\"X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\"\"\"\n",
    "\n",
    "# For 1 channels (GRAY SCALE)\n",
    "X_train_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_train[\"images\"]])\n",
    "X_val_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_val[\"images\"]])\n",
    "X_test_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_test[\"images\"]])\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale numerical data\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_val_num = scaler.transform(X_val_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "attributes = X_train_num.shape[1]\n",
    "height, width = X_train_img[0].shape\n",
    "channels = 1\n",
    "imgs_shape = (height, width, channels)\n",
    "\n",
    "print(\"Images shape: \",imgs_shape)\n",
    "print(\"Attributres: \",attributes)\n",
    "pixel=X_train_img[0].shape[0]\n",
    "print(\"Image size (pixels):\", pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729271720569,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "yymPASjqiCyu",
    "outputId": "6e532688-5640-43fb-a5c6-873746a76c10"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot an example image (e.g., the first image in the array)\n",
    "example_image = X_train_img[0]\n",
    "\n",
    "# Convert the image from BGR (OpenCV default) to RGB for correct color display\n",
    "example_image_rgb = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(example_image_rgb)\n",
    "plt.title(\"Example Image from X_train\")\n",
    "plt.axis('off')  # Hide the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1729271720570,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "8f_NYOCXiCyu",
    "outputId": "632c1bc8-3e06-4c19-e248-172ea36813f3"
   },
   "outputs": [],
   "source": [
    "X_train_img = X_train_img/255\n",
    "X_val_img = X_val_img/255\n",
    "X_test_img = X_test_img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729271720570,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "j34u3al1iCyv"
   },
   "outputs": [],
   "source": [
    "image_size = pixel\n",
    "patch_size = 2\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 32\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 2\n",
    "mlp_head_units = [\n",
    "    64,\n",
    "    32,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729271720570,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "wNMl-A1FiCyv"
   },
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        input_shape = ops.shape(images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        num_patches_h = height // self.patch_size\n",
    "        num_patches_w = width // self.patch_size\n",
    "        patches = keras.ops.image.extract_patches(images, size=self.patch_size)\n",
    "        patches = ops.reshape(\n",
    "            patches,\n",
    "            (\n",
    "                batch_size,\n",
    "                num_patches_h * num_patches_w,\n",
    "                self.patch_size * self.patch_size * channels,\n",
    "            ),\n",
    "        )\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729271720570,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "777mOCgaiCyv"
   },
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = ops.expand_dims(\n",
    "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729271720570,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "CyBagm7piCyw"
   },
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729271720570,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "g80qMV4eiryk"
   },
   "outputs": [],
   "source": [
    "def create_vit_classifier(patch_size, projection_dim, num_heads, transformer_layers, mlp_head_units):\n",
    "    inputs = keras.Input(shape=imgs_shape)\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    num_patches = (imgs_shape[0] // patch_size) ** 2\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=[projection_dim * 2, projection_dim], dropout_rate=0.1)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=features)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Métricas\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# Definición del modelo ViT puro\n",
    "def create_vit_model(patch_size, projection_dim, num_heads, transformer_layers, mlp_head_units):\n",
    "    inputs = keras.Input(shape=imgs_shape)\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder((pixel // patch_size) ** 2, projection_dim)(patches)\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=[projection_dim * 2, projection_dim], dropout_rate=0.1)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    output = Dense(1, activation='sigmoid')(features)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "################# AQUÍ LOS HIPERPARÁMETROS!!! #######\n",
    "################# AQUÍ LOS HIPERPARÁMETROS!!! #######\n",
    "################# AQUÍ LOS HIPERPARÁMETROS!!! #######\n",
    "################# AQUÍ LOS HIPERPARÁMETROS!!! #######\n",
    "################# AQUÍ LOS HIPERPARÁMETROS!!! #######\n",
    "################# AQUÍ LOS HIPERPARÁMETROS!!! #######\n",
    "# Parámetros para grid search\n",
    "patch_sizes = [2]\n",
    "projection_dims = [32, 64, 128]\n",
    "num_heads_list = [2, 4, 6]\n",
    "transformer_layers_list = [2, 4, 6]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Bucle de combinaciones\n",
    "for patch_size, projection_dim, num_heads, transformer_layers in itertools.product(\n",
    "        patch_sizes, projection_dims, num_heads_list, transformer_layers_list):\n",
    "\n",
    "    print(f\"ViT IGTD: patch_size={patch_size}, projection_dim={projection_dim}, num_heads={num_heads}, transformer_layers={transformer_layers}\")\n",
    "\n",
    "    model = create_vit_model(patch_size, projection_dim, num_heads, transformer_layers, [128, 64])\n",
    "    opt = AdamW()\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=X_train_img,\n",
    "        y=y_train,\n",
    "        validation_data=(X_val_img, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopper],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred_probs = model.predict(X_test_img)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    final_metrics = {\n",
    "        \"val_loss\": history.history.get(\"val_loss\", [-1])[-1],\n",
    "        \"val_accuracy\": history.history.get(\"val_accuracy\", [-1])[-1],\n",
    "        \"val_auc\": history.history.get(\"val_auc\", [-1])[-1],\n",
    "        \"val_precision\": history.history.get(\"val_precision\", [-1])[-1],\n",
    "        \"val_recall\": history.history.get(\"val_recall\", [-1])[-1],\n",
    "        \"confusion_tp\": tp,\n",
    "        \"confusion_fp\": fp,\n",
    "        \"confusion_tn\": tn,\n",
    "        \"confusion_fn\": fn,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "\n",
    "    scores = model.evaluate(X_test_img, y_test, verbose=0)\n",
    "    score_dict = {metric.name: score for metric, score in zip(model.metrics, scores)}\n",
    "\n",
    "    result = {\n",
    "        \"patch_size\": patch_size,\n",
    "        \"projection_dim\": projection_dim,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"transformer_layers\": transformer_layers,\n",
    "        **score_dict,\n",
    "        **final_metrics\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    print(f\"Resultados Val -> Loss: {final_metrics['val_loss']:.4f}, Accuracy: {final_metrics['val_accuracy']:.4f}, AUC: {final_metrics['val_auc']:.4f}, Precision: {final_metrics['val_precision']:.4f}, Recall: {final_metrics['val_recall']:.4f}, F1: {f1:.4f}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "# Guardar CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"Resultados/IGTD_ViT.csv\", index=False)\n",
    "print(\"Resultados guardados en Resultados/IGTD_ViT.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
