{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # ViT espera 3 canales\n",
    "    transforms.Resize((224,224)),                 # ViT espera 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])  # normalización básica\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases: 7\n"
     ]
    }
   ],
   "source": [
    "ruta_carpeta_actual = os.getcwd()\n",
    "data_dir = os.path.join(ruta_carpeta_actual, \"PuntosMuestra_CR_tinto_synthetic_images\")\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "num_classes = len(dataset.classes)\n",
    "print(\"Número de clases:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Dividir en train (70%) y test (30%)\n",
    "n = len(dataset)\n",
    "n_train = int(0.7 * n)\n",
    "train_ds, test_ds = random_split(dataset, [n_train, n - n_train])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# from torchvision import models\n",
    "\n",
    "# Crear Vision Transformer base (16x16 patches, imagen 224x224)\n",
    "model = models.vit_b_16(weights=None)   # o weights=\"IMAGENET1K_V1\" si quieres fine-tuning\n",
    "model.heads = nn.Linear(model.heads.head.in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francessca\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Submuestra usada: 482 (train=337, test=145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francessca\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Francessca\\.cache\\huggingface\\hub\\models--timm--vit_tiny_patch16_224.augreg_in21k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3  Acc=0.214\n",
      "Epoch 2/3  Acc=0.345\n",
      "Epoch 3/3  Acc=0.469\n"
     ]
    }
   ],
   "source": [
    "# pip install timm  (si no lo tienes)\n",
    "import timm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ----- 0) Dispositivo -----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ----- 1) Transforms (224, 3 canales) -----\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "])\n",
    "\n",
    "# ----- 2) Dataset y SUBMUESTREO rápido -----\n",
    "data_dir = os.path.join(os.getcwd(), \"PuntosMuestra_CR_tinto_synthetic_images\")\n",
    "full_ds = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "num_classes = len(full_ds.classes)\n",
    "\n",
    "# Toma un subconjunto pequeño y estratificado por carpetas (aprox.)\n",
    "# Aquí: hasta 80 imágenes por clase (ajusta si quieres más/menos)\n",
    "indices = []\n",
    "max_per_class = 80\n",
    "counts = {c:0 for c in range(num_classes)}\n",
    "for i, (_, y) in enumerate(full_ds.samples):\n",
    "    if counts[y] < max_per_class:\n",
    "        indices.append(i); counts[y]+=1\n",
    "small_ds = Subset(full_ds, indices)\n",
    "\n",
    "# Split 70/30\n",
    "n = len(small_ds); n_tr = int(0.7*n)\n",
    "train_ds, test_ds = torch.utils.data.random_split(small_ds, [n_tr, n-n_tr], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=(device.type==\"cuda\"))\n",
    "test_dl  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2, pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "print(f\"Submuestra usada: {len(small_ds)} (train={len(train_ds)}, test={len(test_ds)})\")\n",
    "\n",
    "# ----- 3) Modelo: ViT tiny preentrenado y solo cabeza entrenable -----\n",
    "model = timm.create_model(\"vit_tiny_patch16_224\", pretrained=True, num_classes=num_classes)\n",
    "# Congela todo excepto la cabeza\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.head.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ----- 4) Optimizador y loss -----\n",
    "opt = torch.optim.Adam(model.head.parameters(), lr=2e-4)  # solo cabeza\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "# ----- 5) Entrenamiento corto -----\n",
    "epochs = 3\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    for x,y in train_dl:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model(x), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # Validación\n",
    "    model.eval(); correct=total=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dl:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(1)\n",
    "            correct += (pred==y).sum().item()\n",
    "            total += y.numel()\n",
    "    print(f\"Epoch {ep+1}/{epochs}  Acc={correct/total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMORA DEMASIADO | 1era version\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(5):   # empieza con 5 épocas para probar\n",
    "    # ---- Entrenamiento ----\n",
    "    model.train()\n",
    "    for x,y in train_dl:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model(x), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # ---- Validación ----\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dl:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(1)\n",
    "            correct += (preds==y).sum().item()\n",
    "            total += y.numel()\n",
    "    print(f\"Epoch {epoch+1}: Acc={correct/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          01      0.000     0.000     0.000        26\n",
      "          02      0.000     0.000     0.000         1\n",
      "          03      0.737     0.519     0.609        27\n",
      "          04      0.806     1.000     0.893        25\n",
      "          06      0.371     0.565     0.448        23\n",
      "          07      0.000     0.000     0.000        23\n",
      "          10      0.271     0.800     0.405        20\n",
      "\n",
      "    accuracy                          0.469       145\n",
      "   macro avg      0.312     0.412     0.336       145\n",
      "weighted avg      0.373     0.469     0.394       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francessca\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Francessca\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Francessca\\anaconda3\\envs\\tintoenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ----- 6) Métricas extras (opcional) -----\n",
    "y_true, y_pred = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x,y in test_dl:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        y_true += y.cpu().tolist()\n",
    "        y_pred += pred.cpu().tolist()\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=3, target_names=full_ds.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1era version\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x,y in test_dl:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        preds = model(x).argmax(1)\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b37e52360e4201f7e82df0e4224bd8a8fcfc836b7bbaa6261cc3ae6ad0b97aa1"
  },
  "kernelspec": {
   "display_name": "Python 3.12.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
